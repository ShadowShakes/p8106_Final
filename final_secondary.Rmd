---
title: "P8106 Final Project Primary Analysis"
author: "Shaohan Chen sc5154  XinRen xr2160"
date: "2023-04-28"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE, warning = FALSE)

library(corrplot)
library(leaps)
library(MASS)
library(pROC)
library(caret)
library(glmnet)
library(earth)
library(AppliedPredictiveModeling)
library(rpart.plot)
library(tidyverse)
```

In this part, we give the secondary analysis of the recovery time prediction, where recovery time is taken as a categorical discrete variable.

# Data manipulate and tidy
```{r}
# load original dataset
load("recovery.rdata")

# generate random datasets and merge
set.seed(5154) 
df1 = dat[sample(1:10000, 2000),]
set.seed(2160)
df2 = dat[sample(1:10000, 2000),]
merge_df = rbind(df1, df2) %>% unique()

# tidy the dataset
covid_df = merge_df %>%
  janitor::clean_names() %>%
  na.omit() %>%
  mutate(
    gender = factor(gender, levels = c(0, 1)),
    race = factor(race, levels = c(1, 2, 3, 4)),
    smoking = factor(smoking, levels = c(0, 1, 2)),
    hypertension = factor(hypertension, levels = c(0, 1)),
    diabetes = factor(diabetes, levels = c(0, 1)),
    vaccine = factor(vaccine, levels = c(0, 1)),
    severity = factor(severity, levels = c(0, 1)),
    study = factor(study, levels = c("A", "B", "C")),
    recovery_time = factor(ifelse(recovery_time > 30, "long", "short"), levels = c("short", "long"))
    ) %>%
  select(-id)

# data partition for training and testing
indexTrain = createDataPartition(y = covid_df$recovery_time, p = 0.8, list = FALSE)
train_df = covid_df[indexTrain, ]
test_df = covid_df[-indexTrain, ]

covid_df2 = model.matrix(recovery_time ~., covid_df)[, -1]
x = covid_df2[indexTrain, ]
y = covid_df$recovery_time[indexTrain]

# cv setting
ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 5)
```


# Data Visualization and exploratory analysis
```{r}
# length of dataset
nrow(covid_df)
ncol(covid_df)

# data summary
summary(covid_df)

# feature plot
theme = trellis.par.get()
theme$plot.symbol$col = rgb(.2, .4, .2, .5)
theme$plot.symbol$pch = 16
theme$plot.line$col = rgb(.8, .1, .1, 1)
theme$plot.line$lwd = 2
theme$strip.background$col = rgb(.0, .2, .6, .2)
trellis.par.set(theme)

cor_df = covid_df %>% 
  select(age, height, weight, bmi, sbp, ldl)

featurePlot(x = cor_df,
            y = covid_df$recovery_time,
            scales = list(x = list(relation = "free"),
                          y = list(relation = "free")),
            plot = "box", pch = "|",
            auto.key = list(columns = 2))

# correlation visualization
corrplot(cor(cor_df), 
         method = "circle", 
         type = "lower",
         diag = FALSE,
         tl.cex = 0.5)
```

# Model Fitting

## KNN Model
```{r}
set.seed(5154)

kGrid = expand.grid(k = seq(from = 1, to = 40, by = 1))

# knn model
fit_knn = train(x, y,
                method = "knn",
                trControl = ctrl,
                preProcess = c("center", "scale"),
                tuneGrid = kGrid
                )

# model visual
ggplot(fit_knn)

# best k
fit_knn$finalModel$k

# test error
pred_knn = predict(fit_knn, newdata = x)
test_error_knn = mean((y - pred_knn)^2)
test_error_knn
```

## Ensemble methods

### Bagging

### Boosting

## Support Vector Machines

```{r}
set.seed(5154)
# kernlab
fit_svml = train(recovery_time ~ .,
                 data = train_df,
                 method = "svmLinear",
                 tuneGrid = data.frame(C = exp(seq(-5, 2, len = 50))),
                 preProcess = c("center", "scale"),
                 trControl = ctrl)

plot(fit_svml, highlight = TRUE, xTrans = log)

# e1071
set.seed(5154)
fit_svml2 = train(recovery_time ~ .,
                 data = train_df,
                 method = "svmLinear2",
                 tuneGrid = data.frame(C = exp(seq(-5, 2, len = 50))),
                 preProcess = c("center", "scale"),
                 trControl = ctrl)

plot(fit_svml2, highlight = TRUE, xTrans = log)


grid_svmr = expand.grid(C = exp(seq(1, 7, len = 50)),
                        sigma = exp(seq(-10, -2, len = 20)))

set.seed(5154)
fit_svmr = train(recovery_time ~ .,
                 data = train_df,
                 method = "svmRadialSigma",
                 tuneGrid = grid_svmr,
                 preProcess = c("center", "scale"),
                 trControl = ctrl)

myCol = rainbow(25)
myPar = list(superpose.model = list(col = myCol),
             superpose.line = list(col = myCol))

plot(fit_svmr, highlight = TRUE, par.settings = myPar)

set.seed(5154)
fit_svmr2 = train(recovery_time ~ .,
                 covid_df,
                 subset = indexTrain,
                 method = "svmRadialCost",
                 tuneGrid = data.frame(C = exp(seq(-3, 3, len = 20))),
                 preProcess = c("center", "scale"),
                 trControl = ctrl)

plot(fit_svmr, highlight = TRUE, par.settings = myPar)
```

Compare different SVM models.
```{r}
resamp_svm = resamples(list(svmr = fit_svmr,
                            svmr2 = fit_svmr2,
                            svml = fit_svml,
                            svml2 = fit_svml2))
bwplot(resamp_svm)
```



# Model Selection
```{r}
# model comparison
set.seed(5154)
resamp = resamples(list(cart = fit_rpart,
                        mars = fit_mars, 
                        gam = fit_gam, 
                        pcr = fit_pcr,
                        lasso = fit_lasso, 
                        ridge = fit_ridge, 
                        lm = fit_lm))

# compare training
summary(resamp)
parallelplot(resamp, metric = "RMSE")
bwplot(resamp, metric = "RMSE")
bwplot(resamp, metric = "Rsquared")
```

We select model based on cross-validation error and interpretability.

# Model test performance.
We compare the test performance on test dataset. Reminder: this is only a comparison, we haven't used test data for model selection, unless you named the test data as "validation data".
```{r}
error_test = 
  tibble(
    cart = error_rpart,
    mars = error_mars, 
    gam = error_gam, 
    pcr = error_pcr,
    lasso = error_lasso, 
    ridge = error_ridge, 
    lm = error_lm,
  ) %>%
  pivot_longer(
    cart:lm,
    names_to = 'model',
    values_to = 'value'
  ) 

# ggplot(error_test, aes(x = model, y = value, fill = model)) +
#   geom_bar(stat = 'identity') + 
#   labs(
#     title = "Prediction error on testing set",
#     y = "RMSE"
#   )
```

\ \par

A summary of the above models are listed below:\par
\begin{tabular}{c|c|c}
\hline  
Model & Number of Parameters & Test Error  \\
\hline  
lm & 19  &  `r error_lm`\\
Lasso & 12 & `r error_lasso`\\
Ridge & 19 & `r error_ridge`\\
PCR & 18(comps) & `r error_pcr`\\
GAM & 19 & `r error_gam`\\
MARS & 9(terms) & `r error_mars`\\
CART & 5(internal nodes) & `r error_rpart`\\
\hline
\end{tabular}

```{r}
save.image(file = "midtermdata.RData")
```

