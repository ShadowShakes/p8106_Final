---
title: "P8106 Final Project Secondary Analysis"
author: "Shaohan Chen sc5154  XinRen xr2160"
date: "2023-04-28"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE, warning = FALSE)

library(corrplot)
library(leaps)
library(MASS)
library(pROC)
library(caret)
library(glmnet)
library(earth)
library(AppliedPredictiveModeling)
library(rpart.plot)
library(tidyverse)
```

In this part, we give the secondary analysis of the recovery time prediction, where recovery time is taken as a categorical discrete variable.

# Data manipulate and tidy
```{r}
# load original dataset
load("recovery.rdata")

# generate random datasets and merge
set.seed(5154) 
df1 = dat[sample(1:10000, 2000),]
set.seed(2160)
df2 = dat[sample(1:10000, 2000),]
merge_df = rbind(df1, df2) %>% unique()

# tidy the dataset, and consider response as a binary outcome
covid_df = merge_df %>%
  janitor::clean_names() %>%
  na.omit() %>%
  mutate(
    gender = factor(gender, levels = c(0, 1)),
    race = factor(race, levels = c(1, 2, 3, 4)),
    smoking = factor(smoking, levels = c(0, 1, 2)),
    hypertension = factor(hypertension, levels = c(0, 1)),
    diabetes = factor(diabetes, levels = c(0, 1)),
    vaccine = factor(vaccine, levels = c(0, 1)),
    severity = factor(severity, levels = c(0, 1)),
    study = factor(study, levels = c("A", "B", "C")),
    recovery_time = factor(ifelse(recovery_time > 30, "long", "short"), levels = c("short", "long"))
    ) %>%
  select(-id)

# data partition for training and testing
indexTrain = createDataPartition(y = covid_df$recovery_time, p = 0.8, list = FALSE)
train_df = covid_df[indexTrain, ]
test_df = covid_df[-indexTrain, ]

covid_df2 = model.matrix(recovery_time ~., covid_df)[, -1]
x = covid_df2[indexTrain, ]
y = covid_df$recovery_time[indexTrain]

# cv setting
ctrl_class = trainControl(method = "cv",
                          classProbs = TRUE,
                          summaryFunction = twoClassSummary)
```


# Data Visualization and exploratory analysis
```{r}
# length of dataset
nrow(covid_df)
ncol(covid_df)

# data summary
summary(covid_df)

# feature plot
theme = trellis.par.get()
theme$plot.symbol$col = rgb(.2, .4, .2, .5)
theme$plot.symbol$pch = 16
theme$plot.line$col = rgb(.8, .1, .1, 1)
theme$plot.line$lwd = 2
theme$strip.background$col = rgb(.0, .2, .6, .2)
trellis.par.set(theme)

cor_df = covid_df %>% 
  select(age, height, weight, bmi, sbp, ldl)

featurePlot(x = cor_df,
            y = covid_df$recovery_time,
            scales = list(x = list(relation = "free"),
                          y = list(relation = "free")),
            plot = "box", pch = "|",
            auto.key = list(columns = 2))

# correlation visualization
corrplot(cor(cor_df), 
         method = "circle", 
         type = "lower",
         diag = FALSE,
         tl.cex = 0.5)
```

# Model Fitting

## KNN Model
```{r}
kGrid = expand.grid(k = seq(from = 1, to = 40, by = 1))

set.seed(5154)
fit_knn = train(x, y,
                method = "knn",
                trControl = _class,
                preProcess = c("center", "scale"),
                tuneGrid = kGrid
                )

ggplot(fit_knn)

# best k
fit_knn$finalModel$k

# test error
pred_knn = predict(fit_knn, newdata = x)
test_error_knn = mean((y - pred_knn)^2)
test_error_knn
```


## Logisitc Regression Series

### GLM
```{r}
set.seed(5154)
fit_glm = train(x, y,
                method = "glm",
                metric = "ROC",
                trControl = ctrl_class)
```

### Penalized Logistic Regression
```{r}
glmn_Grid = expand.grid(.alpha = seq(0, 1, length = 21),
                       .lambda = exp(seq(-8, -1, length = 50)))

set.seed(5154)
fit_glmn = train(x, y,
                 method = "glmnet",
                 tuneGrid = glm_Grid,
                 metric = "ROC",
                 trControl = ctrl_class)

fit_glmn$bestTune

myCol = rainbow(25)
myPar = list(superpose.symbol = list(col = myCol),
             uperpose.line = list(col = myCol))

plot(model.glmn, par.settings = myPar, xTrans = function(x) log(x))
```

### GAM
```{r}
set.seed(5154)
fit_gam = train(x, y,
                method = "gam",
                metric = "ROC",
                trControl = ctrl_class)

fit_gam$finalModel

plot(fit_gam$finalModel, select = 3)
```

### MARS
```{r}
set.seed(5154)
fit_mars = train(x, y,
                 method = "earth",
                 tuneGrid = expand.grid(degree = 1:4,
                                        nprune = 2:20),
                 metric = "ROC",
                 trControl = ctrl_class)

plot(fit_mars)

coef(fit_mars$finalModel)
```

### Comparison of tree models
```{r}
resamp_glm = resamples(list(glm = fit_glm,
                            glmnet = fit_glmn,
                            gam = fit_gam,
                            mars = fit_mars))
summary(resamp_glm)
bwplot(resamp_glm)
```


## Discriminant Analysis

### LDA
```{r}
set.seed(5154)
fit_lda = train(x, y,
                method = "lda",
                metric = "ROC",
                trControl = ctrl_class)
```

### QDA
```{r}
set.seed(5154)
fit_qda = train(x, y,
                method = "qda",
                metric = "ROC",
                trControl = ctrl_class)
```

### Naive Bayes
```{r}
nb_Grid = expand.grid(usekernal = c(FALSE, TRUE),
                      fL = 1,
                      adjust = seq(0.2, 3, by = 0.2))

set.seed(5154)
fit_nb = train(x,y,
               method = "nb",
               tuneGrid = nbGrid,
               metric = "ROC",
               trControl = ctrl_class)

plot(fit_nb)
```

### Comparison of DA methods
```{r}
resamp_da = resamples(list(lda = fit_lda,
                            qda = fit_qda,
                            nb = fit_nb))
summary(resamp_da)
bwplot(resamp_da)
```


## Tree Models

### CART
```{r}
set.seed(5154)
fit_rpart = train(recovery_time ~ .,
                  covid_df,
                  subset = indexTrain,
                  method = "rpart",
                  tuneGrid = data.frame(cp = exp(seq(-6, -3, len = 50))),
                  trControl = ctrl_class,
                  metric = "ROC")

ggplot(fit_rpart, highlight = TRUE)

rpart.plot(fit_rpart$finalModel)
```

### CIT
```{r}
set.seed(5154)
fit_ctree = train(recovery_time ~ .,
                  covid_df,
                  subset = indexTrain,
                  method = "ctree",
                  tuneGrid = data.frame(mincriterion = 1 - exp(seq(-2, -1, length = 50))),
                  metric = "ROC",
                  trControl = ctrl_class)

ggplot(fit_ctree, highlight = TRUE)

plot(fit_ctree$finalModel)
```

### Comparison of tree models
```{r}
resamp_tree = resamples(list(cart = fit_cart,
                            cit = fit_ctree))
summary(resamp_tree)
bwplot(resamp_tree)
```


## Ensemble methods for classification

### Bagging
Random forest for classification.
```{r}
rf_grid = expand.grid(mtry = 1:19,
                      splitrule = "gini",
                      min.node.size = seq(from = 2, to = 10, by = 2))

set.seed(5154)
fit_ranfo = train(recovery_time ~ . ,
               train_df,
               method = "ranger",
               tuneGrid = rf_grid,
               metric = "ROC",
               trControl = ctrl_class,
               preProcess = c("center", "scale"))

ggplot(fit_ranfo, highlight = TRUE)
```

### Boosting
AdaBoost is adopted.
```{r}
gbm_grid = expand.grid(n.trees = c(500,1000,2000,3000,4000,5000),
                       interaction.depth = 1:3,
                       shrinkage = c(0.005,0.01),
                       n.minobsinnode = c(1))

fit_boost = train(recovery_time ~ . ,
               covid_df,
               subset = indexTrain,
               method = "gbm",
               tuneGrid = gbm_grid,
               verbose = FALSE,
               distribution = "adaboost",
               metric = "ROC",
               trControl = ctrl_class,
               preProcess = c("center", "scale"))

ggplot(fit_boost, highlight = TRUE)
```

### Comparison of ensemble methods
```{r}
resamp_ens = resamples(list(rf = fit_ranfo,
                            adaboost = fit_boost))
summary(resamp_res)
bwplot(resamp_svm)
```


## Support Vector Machines
```{r}
set.seed(5154)
# kernlab
fit_svml = train(recovery_time ~ .,
                 data = train_df,
                 method = "svmLinear",
                 tuneGrid = data.frame(C = exp(seq(-5, 2, len = 50))),
                 preProcess = c("center", "scale"),
                 trControl = ctrl_class)

plot(fit_svml, highlight = TRUE, xTrans = log)

# e1071
set.seed(5154)
fit_svml2 = train(recovery_time ~ .,
                 data = train_df,
                 method = "svmLinear2",
                 tuneGrid = data.frame(C = exp(seq(-5, 2, len = 50))),
                 preProcess = c("center", "scale"),
                 trControl = ctrl_class)

plot(fit_svml2, highlight = TRUE, xTrans = log)


grid_svmr = expand.grid(C = exp(seq(1, 7, len = 50)),
                        sigma = exp(seq(-10, -2, len = 20)))

set.seed(5154)
fit_svmr = train(recovery_time ~ .,
                 data = train_df,
                 method = "svmRadialSigma",
                 tuneGrid = grid_svmr,
                 preProcess = c("center", "scale"),
                 trControl = ctrl_class)

myCol = rainbow(25)
myPar = list(superpose.model = list(col = myCol),
             superpose.line = list(col = myCol))

plot(fit_svmr, highlight = TRUE, par.settings = myPar)

set.seed(5154)
fit_svmr2 = train(recovery_time ~ .,
                 covid_df,
                 subset = indexTrain,
                 method = "svmRadialCost",
                 tuneGrid = data.frame(C = exp(seq(-3, 3, len = 20))),
                 preProcess = c("center", "scale"),
                 trControl = )

plot(fit_svmr, highlight = TRUE, par.settings = myPar)
```

### Comparison of SVM methods
```{r}
resamp_svm = resamples(list(svmr = fit_svmr,
                            svmr2 = fit_svmr2,
                            svml = fit_svml,
                            svml2 = fit_svml2))
bwplot(resamp_svm)
```



# Model Selection

Compare the best models selected from each section.
```{r}
# model comparison
set.seed(5154)
resamp = resamples(list(cart = fit_rpart,
                        mars = fit_mars, 
                        gam = fit_gam, 
                        pcr = fit_pcr,
                        lasso = fit_lasso, 
                        ridge = fit_ridge, 
                        lm = fit_lm))

# compare training
summary(resamp)
parallelplot(resamp, metric = "RMSE")
bwplot(resamp, metric = "RMSE")
bwplot(resamp, metric = "Rsquared")
```

We select model based on cross-validation error and interpretability.

# Model test performance.
We compare the test performance on test dataset. Reminder: this is only a comparison, we haven't used test data for model selection, unless you named the test data as "validation data".
```{r}
error_test = 
  tibble(
    cart = error_rpart,
    mars = error_mars, 
    gam = error_gam, 
    pcr = error_pcr,
    lasso = error_lasso, 
    ridge = error_ridge, 
    lm = error_lm,
  ) %>%
  pivot_longer(
    cart:lm,
    names_to = 'model',
    values_to = 'value'
  ) 

# ggplot(error_test, aes(x = model, y = value, fill = model)) +
#   geom_bar(stat = 'identity') + 
#   labs(
#     title = "Prediction error on testing set",
#     y = "RMSE"
#   )
```

\ \par

A summary of the above models are listed below:\par
\begin{tabular}{c|c|c}
\hline  
Model & Number of Parameters & Test Error  \\
\hline  
lm & 19  &  `r error_lm`\\
Lasso & 12 & `r error_lasso`\\
Ridge & 19 & `r error_ridge`\\
PCR & 18(comps) & `r error_pcr`\\
GAM & 19 & `r error_gam`\\
MARS & 9(terms) & `r error_mars`\\
CART & 5(internal nodes) & `r error_rpart`\\
\hline
\end{tabular}

```{r}
save.image(file = "midtermdata.RData")
```

