---
title: "P8106 Final Project Primary Analysis"
author: "Shaohan Chen sc5154  XinRen xr2160"
date: "2023-04-28"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE, warning = FALSE)

library(corrplot)
library(leaps)
library(MASS)
library(pROC)
library(caret)
library(glmnet)
library(earth)
library(AppliedPredictiveModeling)
library(rpart.plot)
library(tidyverse)
```

In this part, we give the secondary analysis of the recovery time prediction, where recovery time is taken as a categorical discrete variable.

# Data manipulate and tidy
```{r}
# load original dataset
load("recovery.rdata")

# generate random datasets and merge
set.seed(5154) 
df1 = dat[sample(1:10000, 2000),]
set.seed(2160)
df2 = dat[sample(1:10000, 2000),]
merge_df = rbind(df1, df2) %>% unique()

# tidy the dataset
covid_df = merge_df %>%
  janitor::clean_names() %>%
  na.omit() %>%
  mutate(
    gender = factor(gender, levels = c(0, 1)),
    race = factor(race, levels = c(1, 2, 3, 4)),
    smoking = factor(smoking, levels = c(0, 1, 2)),
    hypertension = factor(hypertension, levels = c(0, 1)),
    diabetes = factor(diabetes, levels = c(0, 1)),
    vaccine = factor(vaccine, levels = c(0, 1)),
    severity = factor(severity, levels = c(0, 1)),
    study = factor(study, levels = c("A", "B", "C")),
    recovery_time = factor(ifelse(recovery_time > 30, "long", "short"), levels = c("short", "long"))
    ) %>%
  select(-id)

# data partition for training and testing
indexTrain = createDataPartition(y = covid_df$recovery_time, p = 0.8, list = FALSE)
train_df = covid_df[indexTrain, ]
test_df = covid_df[-indexTrain, ]

covid_df2 = model.matrix(recovery_time ~., covid_df)[, -1]
x = covid_df2[indexTrain, ]
y = covid_df$recovery_time[indexTrain]

# cv setting
ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 5)
```


# Data Visualization and exploratory analysis
```{r}
# length of dataset
nrow(covid_df)
ncol(covid_df)

# data summary
summary(covid_df)

# feature plot
theme = trellis.par.get()
theme$plot.symbol$col = rgb(.2, .4, .2, .5)
theme$plot.symbol$pch = 16
theme$plot.line$col = rgb(.8, .1, .1, 1)
theme$plot.line$lwd = 2
theme$strip.background$col = rgb(.0, .2, .6, .2)
trellis.par.set(theme)

cor_df = covid_df %>% 
  select(age, height, weight, bmi, sbp, ldl)

featurePlot(x = cor_df,
            y = covid_df$recovery_time,
            scales = list(x = list(relation = "free"),
                          y = list(relation = "free")),
            plot = "box", pch = "|",
            auto.key = list(columns = 2))

# correlation visualization
corrplot(cor(cor_df), 
         method = "circle", 
         type = "lower",
         diag = FALSE,
         tl.cex = 0.5)
```

# Model Fitting

## KNN Model
```{r}
set.seed(5154)

kGrid = expand.grid(k = seq(from = 1, to = 40, by = 1))

# knn model
fit_knn = train(x, y,
                method = "knn",
                trControl = ctrl,
                preProcess = c("center", "scale"),
                tuneGrid = kGrid
                )

# model visual
ggplot(fit_knn)

# best k
fit_knn$finalModel$k

# test error
pred_knn = predict(fit_knn, newdata = x)
test_error_knn = mean((y - pred_knn)^2)
test_error_knn
```

## Linear Model Series

In this section, we adopt linear models including linear regression, Ridge regression and Lasso regression.

### Logistic Regression
```{r}
d
```


## PCR Model
```{r}
set.seed(5154)
fit_pcr = train(x, y,
                method = "pcr",
                trControl = ctrl,
                tuneGrid = data.frame(ncomp = 1:19),
                preProcess = c("center", "scale"))

ggplot(fit_pcr, highlight = TRUE) + theme_bw()

coef(fit_pcr$finalModel)

# importance
plot(varImp(fit_pcr, scale = TRUE))

x2 = model.matrix(recovery_time ~., dat)[-indexTrain, -1]
y2 = dat$recovery_time[-indexTrain]

# test error
pred_pcr = predict(fit_pcr, newdata = x2)
error_pcr = mean((y2 - pred_pcr)^2)
error_pcr
```


## PLS Model
This is not included in final report.
```{r}
# PLS model
set.seed(5154)
fit_pls = train(x, y,
                method = "pls",
                tuneGrid = data.frame(ncomp = 1: 19),
                trControl = ctrl,
                preProcess = c("center", "scale"))

ggplot(fit_pls, highlight = TRUE)

# importance
plot(varImp(fit_pls, scale = TRUE))

# test error
pred_pls = predict(fit_pls, newdata = x2)
error_pls = mean((y2 - pred_pls)^2)
error_pls
```


## GAM Model
```{r}
# GAM model
set.seed(5154)
fit_gam = train(x, y,
                method = "gam",
                trControl = ctrl,
                tuneGrid = data.frame(method = "GCV.Cp", select = c(TRUE,FALSE)),
                preProcess = c("center", "scale"))

fit_gam$bestTune
fit_gam$finalModel
fit_gam$finalModel$coefficients

# test error
pred_gam = predict(fit_gam, newdata = dat2[-indexTrain, ])
error_gam = mean((pred_gam - dat$recovery_time[-indexTrain])^2)
error_gam
```


## MARS Model
```{r}
# MARS model
mars_grid = expand.grid(degree = 1:3,
                        nprune = 2:15)
set.seed(5154)
fit_mars = train(x, y,
                 method = "earth",
                 tuneGrid = mars_grid,
                 trControl = ctrl,
                 preProcess = c("center", "scale"))

ggplot(fit_mars)
fit_mars$bestTune
fit_mars$finalModel
coef(fit_mars$finalModel)

# importance
plot(varImp(fit_mars, scale = TRUE))

# test error
pred_mars = predict(fit_mars, newdata = dat2[-indexTrain, ])
error_mars = mean((pred_mars - dat$recovery_time[-indexTrain])^2)
error_mars
```

## Tree Model
### CART Approach
```{r}
set.seed(5154)
fit_rpart = train(x, y,
                 method = "rpart",
                 tuneGrid = data.frame(cp = exp(seq(-6, -2, length = 50))),
                 trControl = ctrl,
                 preProcess = c("center", "scale"))

ggplot(fit_rpart, highlight = TRUE)
fit_rpart$bestTune$cp
rpart.plot(fit_rpart$finalModel)

# importance
plot(varImp(fit_rpart, scale = TRUE))

# test error
pred_rpart = predict(fit_rpart, newdata = dat2[-indexTrain, ])
error_rpart = mean((pred_rpart - dat$recovery_time[-indexTrain])^2)
error_rpart
```



# Model Selection
```{r}
# model comparison
set.seed(5154)
resamp = resamples(list(cart = fit_rpart,
                        mars = fit_mars, 
                        gam = fit_gam, 
                        pcr = fit_pcr,
                        lasso = fit_lasso, 
                        ridge = fit_ridge, 
                        lm = fit_lm))

# compare training
summary(resamp)
parallelplot(resamp, metric = "RMSE")
bwplot(resamp, metric = "RMSE")
bwplot(resamp, metric = "Rsquared")
```

We select model based on cross-validation error and interpretability.

# Model test performance.
We compare the test performance on test dataset. Reminder: this is only a comparison, we haven't used test data for model selection, unless you named the test data as "validation data".
```{r}
error_test = 
  tibble(
    cart = error_rpart,
    mars = error_mars, 
    gam = error_gam, 
    pcr = error_pcr,
    lasso = error_lasso, 
    ridge = error_ridge, 
    lm = error_lm,
  ) %>%
  pivot_longer(
    cart:lm,
    names_to = 'model',
    values_to = 'value'
  ) 

# ggplot(error_test, aes(x = model, y = value, fill = model)) +
#   geom_bar(stat = 'identity') + 
#   labs(
#     title = "Prediction error on testing set",
#     y = "RMSE"
#   )
```

\ \par

A summary of the above models are listed below:\par
\begin{tabular}{c|c|c}
\hline  
Model & Number of Parameters & Test Error  \\
\hline  
lm & 19  &  `r error_lm`\\
Lasso & 12 & `r error_lasso`\\
Ridge & 19 & `r error_ridge`\\
PCR & 18(comps) & `r error_pcr`\\
GAM & 19 & `r error_gam`\\
MARS & 9(terms) & `r error_mars`\\
CART & 5(internal nodes) & `r error_rpart`\\
\hline
\end{tabular}

```{r}
save.image(file = "midtermdata.RData")
```

